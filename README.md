# Chat Summarization and Insights API

This project provides an API to store, summarize, and extract insights from user chat data using FastAPI, MongoDB, and LLM-based summarization (via OpenAI's GPT-3/4). It supports real-time chat ingestion, conversation retrieval, filtering, and optimization for heavy CRUD operations. Additionally, it provides chat summaries and conversation insights like sentiment analysis and keyword extraction.

## Features
- **Store chat messages** in a MongoDB database.
- **Retrieve and filter chat history** for users.
- **Generate conversation summaries** using an LLM model (GPT-3/4).
- **Real-time chat ingestion** using WebSockets.
- **Conversation insights** like sentiment analysis and keyword extraction.
- **Optimized for heavy CRUD operations** (efficient querying, pagination).
- **Dockerized deployment** for easy setup and usage.
- **Optional Streamlit UI** for chat interaction.

## Requirements
- **Python 3.9+**
- **MongoDB** (Dockerized or locally hosted)
- **OpenAI API Key** (for GPT-3/4 summarization and insights)
- **Docker** (for containerization)

## Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/chat-api.git
   cd chat-api
Create a virtual environment and activate it:

bash
Copy
python -m venv venv
source venv/bin/activate   # On Windows, use: venv\Scripts\activate
Install the required dependencies:

bash
Copy
pip install -r requirements.txt
Set up environment variables: Create a .env file in the project root and add the following (replace the placeholders):

ini
Copy
OPENAI_API_KEY=your_openai_api_key
MONGODB_URI=mongodb://localhost:27017
Run the FastAPI server:

bash
Copy
uvicorn app.main:app --reload
The FastAPI app will be available at http://localhost:8000.

Run the application with Docker (optional): To run the FastAPI app and MongoDB in containers, use Docker Compose:

bash
Copy
docker-compose up --build
The application will be available at http://localhost:8000 once the services are up.

API Endpoints
1. Store Chat Messages
POST /chats

Description: Store raw chat messages in the database.

Request Body:

json
Copy
{
    "user_id": "string",
    "message": "string",
    "timestamp": "ISO Date string",
    "metadata": {"key": "value"}
}
Response:

json
Copy
{
    "conversation_id": "string",
    "status": "success"
}
2. Retrieve Chats
GET /chats/{conversation_id}

Description: Retrieve a specific conversation by conversation_id.

Response:

json
Copy
{
    "conversation_id": "string",
    "user_id": "string",
    "messages": [
        {
            "message_id": "string",
            "message": "string",
            "timestamp": "ISO Date string",
            "metadata": {"key": "value"}
        }
    ]
}
3. Summarize Chat
POST /chats/summarize

Description: Generate a summary for a conversation using GPT-3/4.

Request Body:

json
Copy
{
    "conversation_id": "string"
}
Response:

json
Copy
{
    "summary": "string",
    "insights": {
        "sentiment": "positive/negative/neutral",
        "keywords": ["keyword1", "keyword2"]
    }
}
4. Get User's Chat History
GET /users/{user_id}/chats?page=1&limit=10

Description: Retrieve a paginated list of chats for a user.

Response:

json
Copy
{
    "user_id": "string",
    "chats": [
        {
            "conversation_id": "string",
            "timestamp": "ISO Date string",
            "summary": "short summary of the conversation"
        }
    ]
}
5. Delete Chat
DELETE /chats/{conversation_id}

Description: Delete a specific conversation by conversation_id.

Response:

json
Copy
{
    "status": "success"
}
Docker Setup
Build the Docker image:

bash
Copy
docker-compose build
Run the Docker containers:

bash
Copy
docker-compose up
This will start the FastAPI app and MongoDB service. You can access the API at http://localhost:8000.

Code Structure
/app: Contains the FastAPI application logic (models, routes, database interactions).

/db: MongoDB-related functions (CRUD operations).

/summarizer.py: Functions to interact with GPT-3/4 for chat summarization and insights.

/static: Static files (for Streamlit UI, if applicable).

/docs: API documentation (auto-generated by FastAPI).

/Dockerfile: Docker setup for the FastAPI app.

/docker-compose.yml: Docker Compose configuration for the FastAPI app and MongoDB.

/requirements.txt: Required Python packages for the project.

Notes
Real-time Chat Ingestion: The API supports real-time chat ingestion using WebSockets, allowing clients to push messages directly into the system.

LLM Summarization: The summarization feature uses OpenAI's GPT-3/4 to generate summaries and extract conversation insights (sentiment analysis, keyword extraction).

Optimized for Heavy CRUD Operations: Pagination, indexing, and async database operations ensure the system is scalable and efficient.

License
This project is licensed under the MIT License - see the LICENSE file for details.

yaml
Copy

---

This README provides a clear overview of the setup, usage, and structure of the Chat Summarization and Insights API. You can customize it further based on your project specifics.


